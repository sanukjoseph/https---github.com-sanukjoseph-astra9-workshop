{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f123dcfd",
   "metadata": {},
   "source": [
    "# **Computer Vision with AI: Hands-On Projects**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f89b0e",
   "metadata": {},
   "source": [
    "## **Section 1: Introduction to Computer Vision (Theory)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc15e944",
   "metadata": {},
   "source": [
    "\n",
    "### **What is Computer Vision?**\n",
    "Computer Vision (CV) is a field of artificial intelligence (AI) that enables machines to **see, interpret, and understand visual data** like humans. It involves teaching machines to process images and videos, recognize objects, detect patterns, and make decisions based on visual inputs.\n",
    "\n",
    "- **Why Does Computer Vision Matter?**\n",
    "  - Over **3 billion images** are shared online every day.\n",
    "  - Object recognition accuracy has improved from **50% to 99%** in less than a decade.\n",
    "  - CV is used in **self-driving cars, medical imaging, security systems, augmented reality, and more**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3e5fa",
   "metadata": {},
   "source": [
    "\n",
    "### **How Does Computer Vision Work?**\n",
    "1. **Image Acquisition**: Capturing images or videos using cameras.\n",
    "2. **Preprocessing**: Cleaning and enhancing images (e.g., resizing, filtering).\n",
    "3. **Feature Extraction**: Identifying key patterns or features (e.g., edges, textures).\n",
    "4. **Model Training**: Using machine learning (ML) models, especially **Convolutional Neural Networks (CNNs)**, to learn from labeled datasets.\n",
    "5. **Prediction**: The model makes predictions (e.g., classifying objects, detecting faces).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653cc907",
   "metadata": {},
   "source": [
    "\n",
    "### **Key Applications of Computer Vision**\n",
    "1. **Object Detection**: Identifying objects in images (e.g., detecting cars in traffic).\n",
    "2. **Facial Recognition**: Recognizing or verifying individuals (e.g., unlocking smartphones).\n",
    "3. **Medical Imaging**: Analyzing X-rays, MRIs, and CT scans for diagnostics.\n",
    "4. **Augmented Reality (AR)**: Overlaying digital content on the real world (e.g., Snapchat filters).\n",
    "5. **Autonomous Vehicles**: Enabling cars to navigate and avoid obstacles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b1143",
   "metadata": {},
   "source": [
    "### **Why Learn Computer Vision?**\n",
    "- It’s a **high-demand skill** in industries like healthcare, automotive, and entertainment.\n",
    "- It combines **creativity and technology**, making it fun and rewarding.\n",
    "- You’ll build **real-world applications** that can impact millions of lives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d6b2d",
   "metadata": {},
   "source": [
    "## **Section 2: Setting Up the Environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b0f824",
   "metadata": {},
   "source": [
    "\n",
    "### **Installing Required Libraries**\n",
    "We’ll use popular Python libraries for computer vision:\n",
    "- **OpenCV**: For image processing.\n",
    "- **MediaPipe**: For pose estimation.\n",
    "- **DeepFace**: For emotion detection.\n",
    "- **Transformers**: For image captioning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77bdc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python mediapipe deepface transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ba8fc1",
   "metadata": {},
   "source": [
    "## **Section 3: Hands-On Projects**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a0c2ed",
   "metadata": {},
   "source": [
    "\n",
    "### **Project 1: Face Blurring Tool**\n",
    "#### **Goal**: Detect and blur faces in an image for privacy.\n",
    "\n",
    "#### **Why It’s Useful**:\n",
    "- Protects privacy in images shared online.\n",
    "- Used in security systems and social media platforms.\n",
    "\n",
    "#### **Libraries Used**:\n",
    "- **OpenCV**: A powerful library for image processing.\n",
    "- **Haar Cascades**: A pre-trained model for face detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e266ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Load pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(\"group_photo.jpg\")\n",
    "\n",
    "# Detect faces\n",
    "faces = face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# Blur each face\n",
    "for (x, y, w, h) in faces:\n",
    "    face = image[y:y+h, x:x+w]\n",
    "    face = cv2.GaussianBlur(face, (99, 99), 30)\n",
    "    image[y:y+h, x:x+w] = face\n",
    "\n",
    "# Show result\n",
    "cv2_imshow(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad295777",
   "metadata": {},
   "source": [
    "\n",
    "### **Project 2: AI-Powered Sketch Artist**\n",
    "#### **Goal**: Convert an image into a pencil sketch.\n",
    "\n",
    "#### **Why It’s Useful**:\n",
    "- Turns photos into artistic sketches.\n",
    "- Used in photo editing apps and creative tools.\n",
    "\n",
    "#### **Libraries Used**:\n",
    "- **OpenCV**: For image transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(\"photo.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Invert the grayscale image\n",
    "inverted = cv2.bitwise_not(gray)\n",
    "\n",
    "# Apply Gaussian blur\n",
    "blurred = cv2.GaussianBlur(inverted, (21, 21), 0)\n",
    "\n",
    "# Invert the blurred image and blend with grayscale\n",
    "sketch = cv2.divide(gray, cv2.bitwise_not(blurred), scale=256.0)\n",
    "\n",
    "# Show result\n",
    "cv2_imshow(sketch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc23e63",
   "metadata": {},
   "source": [
    "\n",
    "### **Project 3: Emotion Detector**\n",
    "#### **Goal**: Detect emotions from facial expressions.\n",
    "\n",
    "#### **Why It’s Useful**:\n",
    "- Used in customer feedback systems, mental health apps, and security.\n",
    "\n",
    "#### **Libraries Used**:\n",
    "- **DeepFace**: A pre-trained model for emotion detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74acd294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "\n",
    "# Load image\n",
    "image_path = \"face.jpg\"\n",
    "\n",
    "# Analyze emotions\n",
    "result = DeepFace.analyze(image_path, actions=[\"emotion\"])\n",
    "\n",
    "# Display result\n",
    "print(\"Detected Emotion:\", result[0][\"dominant_emotion\"])\n",
    "Image.open(image_path).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b367d8",
   "metadata": {},
   "source": [
    "\n",
    "### **Project 4: Pose Estimation**\n",
    "#### **Goal**: Detect and visualize human poses in an image.\n",
    "\n",
    "#### **Why It’s Useful**:\n",
    "- Used in fitness apps, animation, and surveillance.\n",
    "\n",
    "#### **Libraries Used**:\n",
    "- **MediaPipe**: A framework for pose detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b6250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(\"person.jpg\")\n",
    "\n",
    "# Process image\n",
    "results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# Draw pose landmarks\n",
    "if results.pose_landmarks:\n",
    "    mp.solutions.drawing_utils.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# Show result\n",
    "cv2_imshow(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52f8afc",
   "metadata": {},
   "source": [
    "\n",
    "### **Project 5: AI-Powered Image Captioning**\n",
    "#### **Goal**: Generate captions for images.\n",
    "\n",
    "#### **Why It’s Useful**:\n",
    "- Helps visually impaired individuals understand images.\n",
    "- Used in social media and content creation.\n",
    "\n",
    "#### **Libraries Used**:\n",
    "- **Transformers**: A library for pre-trained NLP models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1935c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "# Load pre-trained model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# Load image\n",
    "image = Image.open(\"image.jpg\")\n",
    "\n",
    "# Generate caption\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "out = model.generate(**inputs)\n",
    "caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Caption:\", caption)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
